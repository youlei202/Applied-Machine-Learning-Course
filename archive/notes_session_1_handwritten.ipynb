{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 19:58:32.377313: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 19:58:32.411837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 19:58:33.301948: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/leiyo/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFM9JREFUeJzt3X2QVQX9+PHPhW0VFlzUlZh4lCwQNsWBzNT5ghaDJjpDmqOTAubDKGHaTI7lA0gmCoWzYmKWI+RaPtRYmg4pitAkjimm44RajYqjQz6CggICe39/+OMzIE/3XFkeltdrxpk8ez73nHuIfe855+6xVC6XywEAEdFuZ+8AALsOUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUdgDXXXVVVEqlaqanTVrVpRKpXj11Ver3v6KFSvinHPOiW7dukWpVIqLL7646tfiE/PmzYtSqRTz5s3b2bvCbk4UdnPrv0mv/2fvvfeOL3zhCzFixIiYPn16LF++vNX3YcaMGTFr1qyK1588eXLMmjUrLrjggmhubo4zzzyz9XZuF1L0OO2qNvz/24b/XHfddTt719gOSp59tHubNWtWnHXWWfHTn/40DjzwwFizZk3873//i3nz5sWcOXOiV69ecf/998chhxySM2vXro21a9fG3nvvXXh769atizVr1sRee+2VZxuNjY3R0NBQ8U+pRxxxRNTU1MTf//73wtvfnRU9TkW0tLTExx9/HLW1tdGuXev+rFcqlWL48OExevTojZYfdthhMXDgwFbdNq2vZmfvANvH8ccfH0OGDMl//8lPfhJz586NkSNHxkknnRQvvPBCdOjQISIiampqoqamuj/69u3bR/v27T/Tvr711lsxYMCAba63atWqHfJNblf04YcfRl1dXcXrt2vXrqrIV+vLX/5ynHHGGTtse+w4e97ftj3IscceG1deeWUsXrw47rjjjly+uXsKK1eujB/84AfR0NAQnTt3jpNOOineeOONKJVKcdVVV+V6n76n0KdPn/jXv/4V8+fPz8sIw4YN2+z+rL/u/corr8SDDz6Y67/66qv5tbvuuiuuuOKK6N69e3Ts2DE++OCDiIj4wx/+EIMHD44OHTpEQ0NDnHHGGfHGG29s9Ppjx46NTp06xWuvvRYjR46MTp06Rffu3eOmm26KiIjnn38+jj322Kirq4vevXvH73//+20ew4kTJ0a7du3i0Ucf3Wj5eeedF7W1tfHcc89t8zW2dZzWH9P58+fHuHHjomvXrtGjR4+IiFi8eHGMGzcu+vXrFx06dIj9998/vvOd72xyT2dz9xSGDRsWjY2NsWjRojjmmGOiY8eO0b1795g6deom+/faa6/Fiy++WNF7WW/lypWxatWqQjPs+kShjVt/vf7hhx/e6npjx46NG2+8Mb71rW/FlClTokOHDnHCCSds8/WbmpqiR48e0b9//2hubo7m5ua4/PLLN7vuwQcfHM3NzdHQ0BCDBg3K9Q844IBc5+qrr44HH3wwfvSjH8XkyZOjtrY2Zs2aFaeeemq0b98+rr322jj33HPj3nvvjaOPPjqWLVu20TbWrVsXxx9/fPTs2TOmTp0affr0ifHjx8esWbPiuOOOiyFDhsSUKVOic+fOMXr06HjllVe2+v6uuOKKGDRoUJx99tl5f+ahhx6K3/zmNzFhwoQ49NBDt3mMKj1O48aNi0WLFsWECRPixz/+cUREPPXUU7FgwYI47bTTYvr06XH++efHo48+GsOGDYuPPvpom9tdunRpHHfccXHooYfGtGnTon///nHppZfG7NmzN1pv9OjRcfDBB1f0XiI+CVldXV106NAhBgwYUFFg2U2U2a3NnDmzHBHlp556aovr1NfXlw877LD894kTJ5Y3/KNfuHBhOSLKF1988UZzY8eOLUdEeeLEiZts75VXXsllAwcOLA8dOrTife7du3f5hBNO2GjZY489Vo6Ict++fcsfffRRLv/444/LXbt2LTc2NpZXrlyZyx944IFyRJQnTJiQy8aMGVOOiPLkyZNz2dKlS8sdOnQol0ql8l133ZXLX3zxxU3e25Y8//zz5dra2vI555xTXrp0abl79+7lIUOGlNesWVPxey6Xt3yc1h/To48+urx27dqNvrbhsVjviSeeKEdE+fbbb89l64/fY489lsuGDh26yXqrV68ud+vWrXzyySdv9Jrr163EkUceWW5qairfd9995Ztvvrnc2NhYjojyjBkzKppn1+ZMYQ/QqVOnrX4K6a9//WtEfPKT6oYuvPDCVt2vzRkzZkze+4iIePrpp+Ott96KcePGbXTN/IQTToj+/fvHgw8+uMlrnHPOOfm/u3TpEv369Yu6uro49dRTc3m/fv2iS5cu8fLLL29znxobG2PSpElx6623xogRI+Kdd96J3/72t1Xfl9mSc889d5P7NRseizVr1sS7774bBx10UHTp0iWeeeaZbb5mp06dNrr2X1tbG4cffvgm73vevHlRrvAzJ48//nhcdNFFcdJJJ8X5558fCxcujMbGxrjsssti5cqVFb0Guy5R2AOsWLEiOnfuvMWvL168ONq1axcHHnjgRssPOuig1t61TXx6HxYvXhwRn3wT/7T+/fvn19fbe++9N7ocFRFRX18fPXr02OQ+Sn19fSxdurSi/brkkkvi0EMPjX/84x8xceLEim6UF/Xp9x7xyXX7CRMmRM+ePWOvvfaKhoaGOOCAA2LZsmXx/vvvb/M1N/e+991334rfdyVqa2tj/PjxsWzZsli4cOF2e112Dp8+auNef/31eP/993fKN/hqbPiTcTW29MmoLS2v9Kfjl19+Of7zn/9ExCc3rFvD5t77hRdeGDNnzoyLL744vv71r0d9fX2USqU47bTToqWlZZuv+Vnfd6V69uwZERHvvffedn1ddjxnCm1cc3NzRESMGDFii+v07t07WlpaNrnp+t///reibVT729GV6N27d0REvPTSS5t87aWXXsqvt6aWlpYYO3Zs7LPPPnHZZZfFnXfeGffee2/h16nmOP3xj3+MMWPGxLRp0+KUU06J4cOHb/YG+862/nLUp8/S2P2IQhs2d+7cuPrqq+PAAw+M7373u1tcb30wZsyYsdHyG2+8saLt1NXVtdo3qSFDhkTXrl3jV7/6VaxevTqXz549O1544YWKPiH1WV1//fWxYMGC+PWvfx1XX311HHnkkXHBBRfEO++8U+h1qjlO7du33+Sn+htvvDHWrVtX6HW2pdKPpL799tubLFu+fHk0NTVFQ0NDDB48eLvuFzuey0dtxOzZs+PFF1+MtWvXxptvvhlz586NOXPmRO/eveP+++/f6i82DR48OE4++eRoamqKd999N4444oiYP39+/Pvf/46Ibf+EO3jw4Lj55pvjZz/7WRx00EHRtWvXOPbYY7fL+/rc5z4XU6ZMibPOOiuGDh0ap59+erz55ptxww03RJ8+feKHP/zhdtnOlrzwwgtx5ZVXxtixY+PEE0+MiE8+jjlo0KAYN25c3HPPPRW/VjXHaeTIkdHc3Bz19fUxYMCAeOKJJ+KRRx6J/fff/zO9r08bPXp0zJ8/f5uXlW666ab485//HCeeeGL06tUrlixZErfddlu89tpr0dzcHLW1tdt1v9jxRKGNmDBhQkR8ctNvv/32i6985SvR1NQUZ5111lZvMq93++23R7du3eLOO++MP/3pT/HNb34z7r777ujXr982f1N2woQJsXjx4pg6dWosX748hg4dut2iEPHJ71B07Ngxrrvuurj00kujrq4uRo0aFVOmTIkuXbpst+182rp162LMmDHR0NAQTU1NufxLX/pSXHvttXHRRRfFPffcs9GnmrammuN0ww03RPv27eN3v/tdrFq1Ko466qh45JFHtno5sDUdddRRsWDBgrj11lvj3Xffjbq6ujj88MPjtttu265/5uw8nn3EFj377LNx2GGHxR133LHVy09A2+GeAhERm/18eVNTU7Rr1y7+7//+byfsEbAzuHxERERMnTo1Fi5cGMccc0zU1NTE7NmzY/bs2XHeeeflxw3ZvLfffnurN37XX9KD3YHLR0RExJw5c2LSpEmxaNGiWLFiRfTq1SvOPPPMuPzyy7f7b+62NX369Nnkl+g2NHToUP/xG3YbogCf0eOPP77Vxzvsu+++PqrJbkMUAEhuNAOQKr5Y3JqPMgCg9VVyYciZAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpZmfvAGxL+/btC8/U19e3wp5sH+PHj69qrmPHjoVn+vXrV3jm+9//fuGZX/ziF4VnTj/99MIzERGrVq0qPHPdddcVnpk0aVLhmbbAmQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIH4rUxvXr1KjxTW1tbeObII48sPHP00UcXnomI6NKlS+GZk08+uapttTWvv/564Znp06cXnhk1alThmeXLlxeeiYh47rnnCs/Mnz+/qm3tiZwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAglcrlcrmiFUul1t4XNjBo0KCq5ubOnVt4pr6+vqptsWO1tLQUnvne975XeGbFihWFZ6qxZMmSquaWLl1aeOall16qalttTSXf7p0pAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyVNSd1H77bdfVXNPPvlk4Zm+fftWta22pppjt2zZssIzxxxzTOGZiIiPP/648Iwn4LIhT0kFoBBRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABINTt7B9i89957r6q5Sy65pPDMyJEjC8/885//LDwzffr0wjPVevbZZwvPDB8+vPDMhx9+WHhm4MCBhWciIi666KKq5qAIZwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEilcrlcrmjFUqm194WdZJ999ik8s3z58sIzt9xyS+GZiIizzz678MwZZ5xReObOO+8sPAO7k0q+3TtTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAqtnZO8DO98EHH+yQ7bz//vs7ZDsREeeee27hmbvvvrvwTEtLS+EZ2JU5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKpXC6XK1qxVGrtfaGNq6urq2ruL3/5S+GZoUOHFp45/vjjC888/PDDhWdgZ6nk270zBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJA/EY5f3xS9+sfDMM888U3hm2bJlhWcee+yxwjNPP/104ZmIiJtuuqnwTIV/vdlDeCAeAIWIAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBA8kA82qRRo0YVnpk5c2bhmc6dOxeeqdZll11WeOb2228vPLNkyZLCM+wePBAPgEJEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgeSAe/H+NjY2FZ66//vrCM9/4xjcKz1TrlltuKTxzzTXXFJ554403Cs+w43kgHgCFiAIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQPJAPPgMunTpUnjmxBNPrGpbM2fOLDxTzd/buXPnFp4ZPnx44Rl2PA/EA6AQUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQPKUVNhNrF69uvBMTU1N4Zm1a9cWnhkxYkThmXnz5hWe4bPxlFQAChEFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYBU/GlZ0EYdcsghhWdOOeWUwjNf/epXC89EVPdwu2osWrSo8Mzf/va3VtgTdgZnCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASB6Ixy6vX79+hWfGjx9feObb3/524Zlu3boVntmR1q1bV3hmyZIlhWdaWloKz7BrcqYAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkgXhUpZoHwZ1++ulVbauah9v16dOnqm3typ5++unCM9dcc03hmfvvv7/wDG2HMwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQPxGtjPv/5zxeeGTBgQOGZX/7yl4Vn+vfvX3hmV/fkk08Wnvn5z39e1bbuu+++wjMtLS1VbYs9lzMFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgeUrqDrDffvsVnrnllluq2tagQYMKz/Tt27eqbe3KFixYUHhm2rRphWceeuihwjMrV64sPAM7ijMFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkPfqBeF/72tcKz1xyySWFZw4//PDCM927dy88s6v76KOPqpqbPn164ZnJkycXnvnwww8Lz0Bb40wBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBpj34g3qhRo3bIzI60aNGiwjMPPPBA4Zm1a9cWnpk2bVrhmYiIZcuWVTUHFOdMAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAqVQul8sVrVgqtfa+ANCKKvl270wBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUk2lK5bL5dbcDwB2Ac4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEj/D+Li89BkyzL3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select an index of the image you want to visualize\n",
    "image_index = 0  # You can change this index to any value between 0 and the length of x_train or x_test\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(x_train[image_index], cmap='gray')\n",
    "plt.title('Digit from x_train: {}'.format(y_train[image_index]))\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Normalize the pixel values from a scale out of 255 to a scale out of 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current backend is: torch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import keras\n",
    "\n",
    "print(f\"The current backend is: {keras.backend.backend()}\")\n",
    "\n",
    "\n",
    "if keras.backend.backend() != 'torch':\n",
    "    raise RuntimeError(\"Make sure you have Keras 3.0+ (pip install --upgrade keras)\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                 input_shape=input_shape, data_format=\"channels_last\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', data_format=\"channels_last\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "optimizer=tf.keras.optimizers.Adadelta(),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (before training): 2.2962608337402344\n",
      "Test accuracy (before training): 0.11540000140666962\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss (before training):', score[0])\n",
    "print('Test accuracy (before training):', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1798 - loss: 2.2694 - val_accuracy: 0.4627 - val_loss: 2.2259\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3171 - loss: 2.1989 - val_accuracy: 0.5889 - val_loss: 2.1379\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4189 - loss: 2.1071 - val_accuracy: 0.6479 - val_loss: 2.0216\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4866 - loss: 1.9860 - val_accuracy: 0.6835 - val_loss: 1.8704\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5343 - loss: 1.8367 - val_accuracy: 0.7083 - val_loss: 1.6829\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5720 - loss: 1.6656 - val_accuracy: 0.7347 - val_loss: 1.4776\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6040 - loss: 1.4951 - val_accuracy: 0.7577 - val_loss: 1.2802\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6281 - loss: 1.3416 - val_accuracy: 0.7746 - val_loss: 1.1096\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6539 - loss: 1.2115 - val_accuracy: 0.7899 - val_loss: 0.9735\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6774 - loss: 1.1088 - val_accuracy: 0.8011 - val_loss: 0.8675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f804c65d110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size=128, \n",
    "    epochs=10, \n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8674994111061096\n",
      "Test accuracy: 0.8011000156402588\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
